{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection using character 2-, 3- and 4-grams\n",
    "\n",
    "## Rationale\n",
    "\n",
    "In this notebook we describe an experiment that was conducted for the pre-revision paper, but which we have since reanalyzed and decided to be potentially problematic. This negative (or perhaps 'not positive') result is presented for two reasons. In the first place, as a question of methodology, it might be useful to other practitioners who might be considering this kind of approach, and secondly, by presenting the problematic study it might be possible to improve or re-implement it as future work.\n",
    "\n",
    "## Method\n",
    "\n",
    "The design is as follows: we take our corpus of classical Latin poetry, preprocessed and broken into chunks as discussed in the UMAP notebook. We use the complete corpus to train a TF-IDF vectorizer, which should give us an 'overall' feeling for n-gram term frequencies across the corpus. We then reduce the dimensionality to 180 (based on the 'alpha' stat, discussed below) from ~34k via Truncated Singular Value Decomposition (SVD). Finally, we projected a large sample of random chunks from Silius into this space, and calculated a bootstrap p-value for the distance of the Additamentum from that centroid.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Analysing distance from a centroid is generally troublesome in high dimensional space. Since there are so many dimensions in which a vector can diverge, what tends to happen is that no points actually lie \"close\" to the centroid, instead they are distributed near the surface of some hypersphere (sort of like an eggshell). Another problem is that the hyperspheres are not always spheres, they might end up being vague spheroids (eggs, footballs, hamburgers etc). This makes 'pure' distance measurements a little misleading because the clusters are wider along some axes than along others. Mostly we deal with this by using simulation instead of by assuming a distribution (we empirically measure how many random points are further from the centroid rather than making calculations assuming a 'sphere').\n",
    "\n",
    "In this case, it appears that the TF-IDF feature space is not \"stable\" under LSA. This can be seen by considering three different corpora which are all _almost_ the same, but produce contradictory results.\n",
    "\n",
    "## What This Notebook Shows\n",
    "\n",
    "The general conclusion remains unchanged. The lexico-grammatical style of the Additamentum is closer to the Aeneid and Vergilian style than is typical Silian verse, although it is detectably an outlier from both the _Punica_ and the _Aeneid_. There is some doubt as to whether the specific method that was used to produce a $P$-value is reliable, and so, out of an abundance of caution, we have not made a statistical claim. It does not appear that centroid-based measures are stable enough. The dimensionality of the original TF-IDF space is probably too high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:42:42.221447Z",
     "iopub.status.busy": "2021-07-04T01:42:42.220061Z",
     "iopub.status.idle": "2021-07-04T01:42:46.311364Z",
     "shell.execute_reply": "2021-07-04T01:42:46.310402Z",
     "shell.execute_reply.started": "2021-07-04T01:42:42.221217Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from mqdq import ngrams\n",
    "from mqdq import rhyme\n",
    "from mqdq import hexameter_corpus\n",
    "from mqdq import utils\n",
    "from mqdq import line_analyzer as la\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Corpora\n",
    "\n",
    "There are three corpora which are used to build the TF-IDF space. \n",
    "Each 'document' is one 81-line chunk of poetry. The 'terms' are 2, 3 and 4-grams. \n",
    "The corpus is always preprocessed.\n",
    "\n",
    "## Phonetic Transformation\n",
    "\n",
    "All texts are phonetically transformed, which rationalises consonants and \n",
    "vowels, differentiates consonantal u/v and i/j, applies elision and prodelision.\n",
    "\n",
    "## Named Entity Removal\n",
    "\n",
    "To avoid overfitting, proper nouns are replaced with one token '8' which does not otherwise appear. This allows the models to train on eg the number and line-position of proper nouns without overfitting on telltale names. This is particularly important for this project because the names 'Dido', 'Anna', Aeneas etc would otherwise artificially attract the _Additamentum_ towards the Aeneid.\n",
    "\n",
    "There are three test corpora, which are only used to establish the TF-IDF space (the terms themselves, ie the column space, and the inverse document frequencies)\n",
    "\n",
    "## Corpora\n",
    "\n",
    "- `corpus_A` has the Additamentum broken out into a single chunk. The chunk that 'surrounds' the Addit. is made up of some lines before and then some lines immediately following, so that all chunks are still 81 lines.\n",
    "- `corpus_B` segments the _Punica_ normally, so the Addit. is broken over two chunks.\n",
    "- `corpus_C` has the Addit. removed from the Punica (and thus the corpus) entirely.\n",
    "\n",
    "In general, the correct corpus to use seems to be A. If we remove the Addit. before we construct our TF-IDF weights (`corpus_C`) then we would expect new terms in the Addit. to make it seem more unusual. If we split the Addit over two chunks (`corpus_B`) then the document frequency for n-grams native to the Addit. would be doubled, which would again distort the picture. However the change in the overall corpus is so small that _in theory_ it should make very little difference which of the three corpora we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:42:46.313918Z",
     "iopub.status.busy": "2021-07-04T01:42:46.313254Z",
     "iopub.status.idle": "2021-07-04T01:45:55.744939Z",
     "shell.execute_reply": "2021-07-04T01:45:55.744127Z",
     "shell.execute_reply.started": "2021-07-04T01:42:46.313848Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_A = ngrams.geezit_corpus(chunksz=81, drop_propers=True, drop_addit=True)\n",
    "corpus_B = ngrams.geezit_corpus(chunksz=81, drop_propers=True, drop_addit=False)\n",
    "corpus_C = corpus_A.query('Author != \"Unknown\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how the differences between `corpus_A` and `corpus_B` line up - since exactly 81 lines\n",
    "are removed, the differences sync up again by the chunk starting at \n",
    "8.258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:45:55.746968Z",
     "iopub.status.busy": "2021-07-04T01:45:55.746455Z",
     "iopub.status.idle": "2021-07-04T01:45:55.764279Z",
     "shell.execute_reply": "2021-07-04T01:45:55.763096Z",
     "shell.execute_reply.started": "2021-07-04T01:45:55.746908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Author</th>\n",
       "      <th>Work</th>\n",
       "      <th>Bookref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ad magikas etiam fallaks at_kwimproba gentis\\n...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>i_dut turbarum sator at_kwakkendere sollers\\ni...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tantum non striktis mukronibus ulla retardet\\n...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>ibant et laeti pars 8 woke kanebant\\nauktorem ...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Chunk  Author    Work Bookref\n",
       "333  ad magikas etiam fallaks at_kwimproba gentis\\n...  Silius  Punica    8:97\n",
       "334  i_dut turbarum sator at_kwakkendere sollers\\ni...  Silius  Punica   8:258\n",
       "335  tantum non striktis mukronibus ulla retardet\\n...  Silius  Punica   8:339\n",
       "336  ibant et laeti pars 8 woke kanebant\\nauktorem ...  Silius  Punica   8:420"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_A.loc[333:336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:45:55.766345Z",
     "iopub.status.busy": "2021-07-04T01:45:55.765986Z",
     "iopub.status.idle": "2021-07-04T01:45:55.783220Z",
     "shell.execute_reply": "2021-07-04T01:45:55.780489Z",
     "shell.execute_reply.started": "2021-07-04T01:45:55.766280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Author</th>\n",
       "      <th>Work</th>\n",
       "      <th>Bookref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ad magikas etiam fallaks at_kwimproba gentis\\n...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>praeterea ne falsa putes haek fingere 8\\nhaud ...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>i_dut turbarum sator at_kwakkendere sollers\\ni...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tantum non striktis mukronibus ulla retardet\\n...</td>\n",
       "      <td>Silius</td>\n",
       "      <td>Punica</td>\n",
       "      <td>8:340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Chunk  Author    Work Bookref\n",
       "333  ad magikas etiam fallaks at_kwimproba gentis\\n...  Silius  Punica    8:97\n",
       "334  praeterea ne falsa putes haek fingere 8\\nhaud ...  Silius  Punica   8:178\n",
       "335  i_dut turbarum sator at_kwakkendere sollers\\ni...  Silius  Punica   8:259\n",
       "336  tantum non striktis mukronibus ulla retardet\\n...  Silius  Punica   8:340"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_B.loc[333:336]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Distributions\n",
    "\n",
    "For the calculation of centroids etc it is better to have a large sampled distribution, so we take $180^2$ contiguous chunks from the Punica (all lines, so parts of the Addit will appear in some sample chunks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:45:55.785261Z",
     "iopub.status.busy": "2021-07-04T01:45:55.784800Z",
     "iopub.status.idle": "2021-07-04T01:46:26.231053Z",
     "shell.execute_reply": "2021-07-04T01:46:26.230427Z",
     "shell.execute_reply.started": "2021-07-04T01:45:55.785102Z"
    }
   },
   "outputs": [],
   "source": [
    "# The full Punica, with named entities removed. This is what will be used to create\n",
    "# the sample distribution. We DO include the Additamentum here because that gives us\n",
    "# a more conservative measure (the result is much stronger when the Additamentum is \n",
    "# not included in the comparison data, as one might expect).\n",
    "\n",
    "with open('SIL-puni.xml') as fh:\n",
    "    soup = BeautifulSoup(fh,\"xml\")\n",
    "ll = utils.clean(soup('line'))\n",
    "ll_np = ngrams._remove_propers(ll)\n",
    "\n",
    "# And the same for the Aeneid\n",
    "\n",
    "with open('VERG-aene.xml') as fh:\n",
    "    soup = BeautifulSoup(fh,\"xml\")\n",
    "aen_ll = utils.clean(soup('line'))\n",
    "aen_ll_np = ngrams._remove_propers(aen_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:26.232526Z",
     "iopub.status.busy": "2021-07-04T01:46:26.232250Z",
     "iopub.status.idle": "2021-07-04T01:46:39.296864Z",
     "shell.execute_reply": "2021-07-04T01:46:39.295585Z",
     "shell.execute_reply.started": "2021-07-04T01:46:26.232487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ordior arma kwibus kaelo se gloria tollit\\n',\n",
       " 'aeneadum patiturkwe feroks oenotria jura\\n',\n",
       " 'kartago da musa dekus memorare laborum\\n',\n",
       " 'anti_kwesperiae kwantos_kwad bella krearit\\n',\n",
       " 'et kwot roma wiros sakri kum perfida pakti\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison - text with and without named entity removal\n",
    "# As can be seen, there are some 'false positives', eg decus\n",
    "# and gloria are treated as proper nouns because they are\n",
    "# sometimes anthropomorphised.\n",
    "\n",
    "ll_p = ngrams._just_stringify(ll, type='phon')\n",
    "ll_p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:39.298598Z",
     "iopub.status.busy": "2021-07-04T01:46:39.298257Z",
     "iopub.status.idle": "2021-07-04T01:46:39.322566Z",
     "shell.execute_reply": "2021-07-04T01:46:39.318652Z",
     "shell.execute_reply.started": "2021-07-04T01:46:39.298549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ordior arma kwibus kaelo se 8 tollit\\n',\n",
       " '8 patiturkwe feroks 8 jura\\n',\n",
       " '8 da 8 8 memorare laborum\\n',\n",
       " 'anti_kwesperiae kwantos_kwad bella krearit\\n',\n",
       " 'et kwot 8 wiros sakri kum perfida pakti\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_np[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:39.325638Z",
     "iopub.status.busy": "2021-07-04T01:46:39.325401Z",
     "iopub.status.idle": "2021-07-04T01:46:39.340312Z",
     "shell.execute_reply": "2021-07-04T01:46:39.339274Z",
     "shell.execute_reply.started": "2021-07-04T01:46:39.325598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Isolate the lines of the Additamentum, which we will need for various things\n",
    "\n",
    "addit_lines = ll_np[5230:5311]\n",
    "ad_chunk = ''.join(addit_lines)\n",
    "puni_na = ll_np[:5230] + ll_np[5311:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:39.342856Z",
     "iopub.status.busy": "2021-07-04T01:46:39.342371Z",
     "iopub.status.idle": "2021-07-04T01:46:39.361343Z",
     "shell.execute_reply": "2021-07-04T01:46:39.356615Z",
     "shell.execute_reply.started": "2021-07-04T01:46:39.342800Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_chunks(ll, n, chunksz, rng):\n",
    "    '''\n",
    "    Take a contiguous sample of n sets, each with length chunksz from the set of lines ll.\n",
    "    '''\n",
    "    \n",
    "    sample = []\n",
    "    for x in range(n):\n",
    "        chunk_head = rng.randint(0,len(ll)-chunksz)\n",
    "        sample.append(''.join(ll[chunk_head:chunk_head+chunksz]))\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:39.362709Z",
     "iopub.status.busy": "2021-07-04T01:46:39.362505Z",
     "iopub.status.idle": "2021-07-04T01:46:40.740374Z",
     "shell.execute_reply": "2021-07-04T01:46:40.739731Z",
     "shell.execute_reply.started": "2021-07-04T01:46:39.362676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sampled distribution, used to calculate centroid etc. Given that we will reduce to 180\n",
    "# dimensions (discussed next) we take 180^2 samples. This is not always important, but\n",
    "# in some cases it is. See https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html\n",
    "\n",
    "DIST_ADDIT_NOPROPS = sample_chunks(ll_np, 180*180, 81, np.random.RandomState(seed=1234))\n",
    "DIST_PUNI_NA_10K = sample_chunks(puni_na, 10_000, 81, np.random.RandomState(seed=1234))\n",
    "DIST_AEN = sample_chunks(aen_ll_np, 180*180, 81, np.random.RandomState(seed=1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why 180 dimensions for the LSA?\n",
    "\n",
    "Here we will examine the spectrum of the data. We have 793 rows and around 34k columns once we do the TF-IDF transformation, which is massively overspecified. Standard approach is to reduce that feature space, and the typical 'Latent Semantic Analysis' approach does that dimension reduction using Truncated Singular Value Decomposition. Essentially we get the eigenvectors from the data matrix in descending order of eigenvalue and use the first _n_ of them, but how many is reasonable? The scikit documentation says 'For LSA, a value of 100 is recommended', but a more scientific approach is to graph the 'alpha' stat $\\alpha = \\frac{\\sigma_1^2}{\\sum_i{\\sigma_i^2}}$ for each singular value $\\sigma_n$. Intuitively, this $\\alpha$ describes 'the eigenvectors where most of the variation happens' for some definition of most, and with the competing constraint that we would like to reduce the dimension as much as we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:46:40.748534Z",
     "iopub.status.busy": "2021-07-04T01:46:40.747795Z",
     "iopub.status.idle": "2021-07-04T01:47:36.953898Z",
     "shell.execute_reply": "2021-07-04T01:47:36.952966Z",
     "shell.execute_reply.started": "2021-07-04T01:46:40.748217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='char', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(2, 4), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=True,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=1000,\n",
       "                              n_iter=5, random_state=None, tol=0.0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        use_idf=True,\n",
    "        sublinear_tf=True,\n",
    "        norm='l2', \n",
    "        analyzer='char',\n",
    "        ngram_range=(2,4),\n",
    "    ),\n",
    "    TruncatedSVD(1000),\n",
    ")\n",
    "    \n",
    "p.fit(corpus_A.Chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:36.957185Z",
     "iopub.status.busy": "2021-07-04T01:47:36.955477Z",
     "iopub.status.idle": "2021-07-04T01:47:36.966643Z",
     "shell.execute_reply": "2021-07-04T01:47:36.965908Z",
     "shell.execute_reply.started": "2021-07-04T01:47:36.957106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793 singular values.\n",
      "Sum is 652.57. First Eigenvalue is 16.12.\n"
     ]
    }
   ],
   "source": [
    "# What does the spectrum look like (roughly)?\n",
    "\n",
    "param_dir = p.steps[1][1]\n",
    "svs = param_dir.singular_values_\n",
    "print(\"%d singular values.\" % len(svs))\n",
    "print(\"Sum is %.2f. First Eigenvalue is %.2f.\" % (sum(svs), svs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:36.968679Z",
     "iopub.status.busy": "2021-07-04T01:47:36.967942Z",
     "iopub.status.idle": "2021-07-04T01:47:36.988323Z",
     "shell.execute_reply": "2021-07-04T01:47:36.987402Z",
     "shell.execute_reply.started": "2021-07-04T01:47:36.968610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate alpha for each n in 'the first n singular values'\n",
    "\n",
    "alpha = []\n",
    "for i,x in enumerate(svs):\n",
    "    # The svs in scikit are already squared.\n",
    "    alpha.append(svs[0]/svs[:i+1].sum())\n",
    "    \n",
    "evs = p.steps[1][1].explained_variance_ratio_\n",
    "ev = []\n",
    "for i,x in enumerate(evs):\n",
    "    ev.append(evs[:i+1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:36.993705Z",
     "iopub.status.busy": "2021-07-04T01:47:36.991450Z",
     "iopub.status.idle": "2021-07-04T01:47:37.001519Z",
     "shell.execute_reply": "2021-07-04T01:47:37.000766Z",
     "shell.execute_reply.started": "2021-07-04T01:47:36.993629Z"
    }
   },
   "outputs": [],
   "source": [
    "# I don't do much matplot, but this is just a quick exploration\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Any value from 100 to 200 is probably reasonable based on the 'elbow' of the alpha curve. Since the explained variance climbs extremely slowly, we have preferred higher values. In a separate experiment we found that p-values for the one-class outlier experiment tended to stabilize at about 180 dimensions, so that is the number we have chosen for classification tests, but the number really isn't that important overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:37.005095Z",
     "iopub.status.busy": "2021-07-04T01:47:37.002855Z",
     "iopub.status.idle": "2021-07-04T01:47:37.542981Z",
     "shell.execute_reply": "2021-07-04T01:47:37.542220Z",
     "shell.execute_reply.started": "2021-07-04T01:47:37.005022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,6),dpi=144)\n",
    "plt.plot(np.arange(0,len(svs)),alpha,label='alpha')\n",
    "plt.plot(np.arange(0, len(evs)),ev,label=\"explained variance\")\n",
    "plt.legend(bbox_to_anchor=[0.9,0.55])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Initial Experiment\n",
    "\n",
    "Based on the spectrum analysis, we defined the experiment as follows:\n",
    "- Create a TF-IDF feature space based on the full corpus (since there is no reason to suppose the _Additamentum_ is by Silius)\n",
    "- Create a sampled distribution of continguous 81-line chunks from Silius\n",
    "- Transform the sampled distribution with TF-IDF, and perform SVD at 180 dimensions\n",
    "- Project the transformed _Additamentum_ into the same space\n",
    "- Calculate an empirical p-value by determining how many of the sampled chunks are further from the geometric median of the Silian points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:37.544721Z",
     "iopub.status.busy": "2021-07-04T01:47:37.544051Z",
     "iopub.status.idle": "2021-07-04T01:47:37.564379Z",
     "shell.execute_reply": "2021-07-04T01:47:37.563591Z",
     "shell.execute_reply.started": "2021-07-04T01:47:37.544495Z"
    }
   },
   "outputs": [],
   "source": [
    "# The geometric median is the L1 equivalent of the Euclidean distance. Just as the\n",
    "# median is more robust in the presence of outliers, so the geometric median is\n",
    "# more robust than the L2 centroid.\n",
    "\n",
    "# Unfortunately, it is much more annoying to calculate. The idea is to find a point\n",
    "# that minimizes the straight line distance to every point we're considering. The \n",
    "# algorithm, boiled down, picks a point and then moves it around until the distance\n",
    "# stops getting smaller. \n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/30299267/geometric-median-of-multidimensional-points\n",
    "    [QUOTING THE POST AUTHOR]\n",
    "    I implemented Yehuda Vardi and Cun-Hui Zhang's algorithm for the geometric median,\n",
    "    described in their paper \"The multivariate L1-median and associated data depth\".\n",
    "    Everything is vectorized in numpy, so should be very fast. I didn't implement \n",
    "    weights - only unweighted points.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:47:37.568010Z",
     "iopub.status.busy": "2021-07-04T01:47:37.567001Z",
     "iopub.status.idle": "2021-07-04T01:55:59.157591Z",
     "shell.execute_reply": "2021-07-04T01:55:59.154969Z",
     "shell.execute_reply.started": "2021-07-04T01:47:37.567931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 1.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    norm='l2', \n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4),\n",
    ")\n",
    "lsa = make_pipeline(\n",
    "    TruncatedSVD(180, n_iter=10, random_state=42),\n",
    "    #Normalizer(copy=False),\n",
    ")\n",
    "\n",
    "\n",
    "# fit the TF-IDF weights etc to this corpus.\n",
    "corpus_vecs = tfidf.fit_transform(corpus_A.Chunk)\n",
    "# calculate the eigenvectors based only on the actual corpus\n",
    "lsa.fit(corpus_vecs)\n",
    "puni_dist_tfidf = tfidf.transform(DIST_ADDIT_NOPROPS)\n",
    "dist_vecs_puni = lsa.transform(puni_dist_tfidf)\n",
    "# to calculate the centroid, take the geometric median in full dimension, then transform\n",
    "cent_puni = geometric_median(np.asarray(puni_dist_tfidf.todense())).reshape(1,-1)\n",
    "cent_puni_svd = lsa.transform(cent_puni)\n",
    "\n",
    "ad_vec = lsa.transform(tfidf.transform([ad_chunk]))\n",
    "ad_dist_puni = pairwise_distances(cent_puni_svd, ad_vec, metric='l2')[0][0]\n",
    "\n",
    "puni_dists = [pairwise_distances(cent_puni_svd, x.reshape(1,-1), metric='l2')[0][0] for x in dist_vecs_puni]\n",
    "print(\"Percentage of PUNICA points FURTHER from Punica (than Addit): %2.2f\" % (len([x for x in puni_dists if x > ad_dist_puni])/len(puni_dists)*100))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "The result indicated that the _Additamentum_ is an outlier with bootstrap $P < 0.05$. However, on further investigation, we discovered that the LSA space is extremely sensitive to the TF-IDF feature space. While it is clear from the classifier tests that clustering performance is strong, the relative locations of various points (and perhaps their centroids in general) seems to be very unstable.\n",
    "\n",
    "In the further experiments below we show:\n",
    "- Depending on the corpus (`A`, `B` or `C`), the geometry of the SVD space changes wildly\n",
    "- geometric outlier methods (as a single-class problem) might not be reliable in these spaces\n",
    "- The TF-IDF space itself is stable (the results don't change much between the three corpora)\n",
    "\n",
    "Unfortunately, the dimensionality of the full TF-IDF space is too high to use geometric methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T01:55:59.168330Z",
     "iopub.status.busy": "2021-07-04T01:55:59.167391Z",
     "iopub.status.idle": "2021-07-04T02:38:49.404905Z",
     "shell.execute_reply": "2021-07-04T02:38:49.393625Z",
     "shell.execute_reply.started": "2021-07-04T01:55:59.167672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addit distance from Puni centroid: 0.6982\n",
      "Addit distance from Aeneid centroid: 0.7032\n",
      "Distance from Puni centroid to Aeneid centroid: 0.2958\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 89.12\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 1.32\n",
      "\n",
      "Addit distance from Puni centroid: 0.5655\n",
      "Addit distance from Aeneid centroid: 0.5791\n",
      "Distance from Puni centroid to Aeneid centroid: 0.2958\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 4.20\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 63.51\n",
      "\n",
      "Addit distance from Puni centroid: 0.3146\n",
      "Addit distance from Aeneid centroid: 0.3239\n",
      "Distance from Puni centroid to Aeneid centroid: 0.2958\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 0.04\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 99.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    norm='l2', \n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4),\n",
    ")\n",
    "lsa = make_pipeline(\n",
    "    TruncatedSVD(180, n_iter=10, random_state=42),\n",
    "    Normalizer(copy=False),\n",
    ")\n",
    "\n",
    "for cp in [corpus_A, corpus_B, corpus_C]:\n",
    "\n",
    "    # fit the TF-IDF weights etc to this corpus.\n",
    "    corpus_vecs = tfidf.fit_transform(cp.Chunk)\n",
    "    # calculate the eigenvectors based only on the actual corpus\n",
    "    lsa.fit(corpus_vecs)\n",
    "    puni_dist_tfidf = tfidf.transform(DIST_ADDIT_NOPROPS)\n",
    "    dist_vecs_puni = lsa.transform(puni_dist_tfidf)\n",
    "    # to calculate the centroid, take the geometric median in full dimension, then transform\n",
    "    cent_puni = geometric_median(np.asarray(puni_dist_tfidf.todense())).reshape(1,-1)\n",
    "    cent_puni_svd = lsa.transform(cent_puni)\n",
    "\n",
    "    dist_aen_tfidf = tfidf.transform(DIST_AEN)\n",
    "    dist_vecs_aen = lsa.transform(dist_aen_tfidf)\n",
    "    cent_aen = geometric_median(np.asarray(dist_aen_tfidf.todense())).reshape(1,-1)\n",
    "    cent_aen_svd = lsa.transform(cent_aen)\n",
    "\n",
    "    ad_vec = lsa.transform(tfidf.transform([ad_chunk]))\n",
    "    ad_dist_puni = pairwise_distances(cent_puni_svd, ad_vec, metric='l2')[0][0]\n",
    "    ad_dist_aen = pairwise_distances(cent_aen_svd, ad_vec, metric='l2')[0][0]\n",
    "\n",
    "    print(\"Addit distance from Puni centroid: %.4f\" % ad_dist_puni)\n",
    "    print(\"Addit distance from Aeneid centroid: %.4f\" % ad_dist_aen)\n",
    "\n",
    "    print(\"Distance from Puni centroid to Aeneid centroid: %.4f\" % pairwise_distances(cent_aen_svd, cent_puni_svd, metric='l2')[0][0])\n",
    "\n",
    "    aen_dists = [pairwise_distances(cent_aen_svd, x.reshape(1,-1), metric='l2')[0][0] for x in dist_vecs_puni]\n",
    "    print(\"Percentage of PUNICA points CLOSER to Aeneid (than Addit): %2.2f\" % (len([x for x in aen_dists if x < ad_dist_aen])/len(aen_dists)*100))\n",
    "\n",
    "    puni_dists = [pairwise_distances(cent_puni_svd, x.reshape(1,-1), metric='l2')[0][0] for x in dist_vecs_puni]\n",
    "    print(\"Percentage of PUNICA points FURTHER from Punica (than Addit): %2.2f\" % (len([x for x in puni_dists if x > ad_dist_puni])/len(puni_dists)*100))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric outlier methods on SVD projections of high-dimensional data are confusing\n",
    "\n",
    "Looking at the results above, it seems clear that the geometry of the truncated SVD space is extremely sensitive to the input TF-IDF data, and metric-topological methods (centroid etc) seem fragile. Some other notes:\n",
    "- In the first two projections, the Addit is further from either centroid that the centroids are from each other. Although this is difficult to interpret, it _might_ support the theory that it is not written by either author, but is derivative of both.\n",
    "- In the results from `corpus_C` (not including the Addit in the TF-IDF training data), the fact that 99.9% of Punica points are further from the Punica centroid than the Addit is, itself, very strange. Points in high dimension usually lie in a thin 'shell' at quite a distance from the centroid. This is a consequence of the way high-dimensional metrics work (there are many 'directions' in which the data can diverge, so the 'minimum' distance given normal noise is quite far from the centroid). It is much more likely that the Addit is a point that is diverging from a different centroid entirely (which would support the claim of interpolation)\n",
    "- Further to that point, the distances from the centroid appear (based on a QQ plot, not shown) to be normally distributed about a mean. In that sense, a point being unusually close to the centroid is also an 'outlier' in the statistical sense.\n",
    "\n",
    "My current hypothesis is that a small change in a couple of eigenvalues means that a completely different eigenbasis is chosen, since the 'best' n vectors (ie with the highest eigenvalues) are the ones chosen for the reduction and that the position of anomalous points therefore varies greatly. In addition, the SVD process suffers from 'sign indeterminancy' in that the 'directions' in the basis can be switched, ie the same model, fit twice, might produce the same basis except with a few directions swapped, which would completely change the position of points with strong components in those directions.\n",
    "\n",
    "In general, the first experiment still seems to be the 'correct' one, but more broadly I am unsure, at this time, that metric-topological methods are appropriate for SVD projections of very high dimensional data (or at least not for this very high dimensional data) and so I have chosen not to present these results.\n",
    "\n",
    "## Repeating the experiment at 100 dimensions (per the documentation) - no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T02:38:49.441405Z",
     "iopub.status.busy": "2021-07-04T02:38:49.440234Z",
     "iopub.status.idle": "2021-07-04T03:21:38.524529Z",
     "shell.execute_reply": "2021-07-04T03:21:38.515219Z",
     "shell.execute_reply.started": "2021-07-04T02:38:49.441322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addit distance from Puni centroid: 0.4160\n",
      "Addit distance from Aeneid centroid: 0.4199\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1729\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 96.73\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 0.35\n",
      "\n",
      "Addit distance from Puni centroid: 0.3166\n",
      "Addit distance from Aeneid centroid: 0.3258\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1729\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 15.23\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 45.44\n",
      "\n",
      "Addit distance from Puni centroid: 0.1608\n",
      "Addit distance from Aeneid centroid: 0.1684\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1730\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 0.10\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 99.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    norm='l2', \n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4),\n",
    ")\n",
    "lsa = make_pipeline(\n",
    "    TruncatedSVD(100, n_iter=10, random_state=42),\n",
    "    #Normalizer(copy=False),\n",
    ")\n",
    "\n",
    "for cp in [corpus_A, corpus_B, corpus_C]:\n",
    "\n",
    "    # fit the TF-IDF weights etc to this corpus.\n",
    "    corpus_vecs = tfidf.fit_transform(cp.Chunk)\n",
    "    # calculate the eigenvectors based only on the actual corpus\n",
    "    lsa.fit(corpus_vecs)\n",
    "    puni_dist_tfidf = tfidf.transform(DIST_ADDIT_NOPROPS)\n",
    "    dist_vecs_puni = lsa.transform(puni_dist_tfidf)\n",
    "    # to calculate the centroid, take the geometric median in full dimension, then transform\n",
    "    cent_puni = geometric_median(np.asarray(puni_dist_tfidf.todense())).reshape(1,-1)\n",
    "    cent_puni_svd = lsa.transform(cent_puni)\n",
    "\n",
    "    dist_aen_tfidf = tfidf.transform(DIST_AEN)\n",
    "    dist_vecs_aen = lsa.transform(dist_aen_tfidf)\n",
    "    cent_aen = geometric_median(np.asarray(dist_aen_tfidf.todense())).reshape(1,-1)\n",
    "    cent_aen_svd = lsa.transform(cent_aen)\n",
    "\n",
    "    ad_vec = lsa.transform(tfidf.transform([ad_chunk]))\n",
    "    ad_dist_puni = pairwise_distances(cent_puni_svd, ad_vec, metric='l2')[0][0]\n",
    "    ad_dist_aen = pairwise_distances(cent_aen_svd, ad_vec, metric='l2')[0][0]\n",
    "\n",
    "    print(\"Addit distance from Puni centroid: %.4f\" % ad_dist_puni)\n",
    "    print(\"Addit distance from Aeneid centroid: %.4f\" % ad_dist_aen)\n",
    "\n",
    "    print(\"Distance from Puni centroid to Aeneid centroid: %.4f\" % pairwise_distances(cent_aen_svd, cent_puni_svd, metric='l2')[0][0])\n",
    "\n",
    "    aen_dists = [pairwise_distances(cent_aen_svd, x.reshape(1,-1), metric='l2')[0][0] for x in dist_vecs_puni]\n",
    "    print(\"Percentage of PUNICA points CLOSER to Aeneid (than Addit): %2.2f\" % (len([x for x in aen_dists if x < ad_dist_aen])/len(aen_dists)*100))\n",
    "\n",
    "    puni_dists = [pairwise_distances(cent_puni_svd, x.reshape(1,-1), metric='l2')[0][0] for x in dist_vecs_puni]\n",
    "    print(\"Percentage of PUNICA points FURTHER from Punica (than Addit): %2.2f\" % (len([x for x in puni_dists if x > ad_dist_puni])/len(puni_dists)*100))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus differences make little difference using un-reduced TF-IDF data\n",
    "\n",
    "Intuitively, such a small difference between the corpora should have made little difference, and indeed it makes little difference to the results taken in full dimensionality, as verified below. The variability is somehow a result of the SVD process.\n",
    "\n",
    "This is NOT an argument for using centroid measures (distance-metric based measures in general) on the un-reduced data, since the dimension is vastly overspecified compared to the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T03:21:38.565136Z",
     "iopub.status.busy": "2021-07-04T03:21:38.561541Z",
     "iopub.status.idle": "2021-07-04T04:04:59.729750Z",
     "shell.execute_reply": "2021-07-04T04:04:59.715272Z",
     "shell.execute_reply.started": "2021-07-04T03:21:38.563545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addit distance from Puni centroid: 0.8196\n",
      "Addit distance from Aeneid centroid: 0.8259\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1763\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 44.59\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 11.07\n",
      "\n",
      "Addit distance from Puni centroid: 0.8195\n",
      "Addit distance from Aeneid centroid: 0.8258\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1763\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 44.19\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 11.25\n",
      "\n",
      "Addit distance from Puni centroid: 0.8197\n",
      "Addit distance from Aeneid centroid: 0.8260\n",
      "Distance from Puni centroid to Aeneid centroid: 0.1764\n",
      "Percentage of PUNICA points CLOSER to Aeneid (than Addit): 45.15\n",
      "Percentage of PUNICA points FURTHER from Punica (than Addit): 10.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    norm='l2', \n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4),\n",
    ")\n",
    "\n",
    "\n",
    "for cp in [corpus_A, corpus_B, corpus_C]:\n",
    "\n",
    "    # fit the TF-IDF weights etc to this corpus.\n",
    "    corpus_vecs = tfidf.fit_transform(cp.Chunk)\n",
    "    # calculate the eigenvectors based only on the actual corpus\n",
    "    puni_dist_tfidf = tfidf.transform(DIST_ADDIT_NOPROPS)\n",
    "    # to calculate the centroid, take the geometric median in full dimension, then transform\n",
    "    cent_puni = geometric_median(np.asarray(puni_dist_tfidf.todense())).reshape(1,-1)\n",
    "\n",
    "    dist_aen_tfidf = tfidf.transform(DIST_AEN)\n",
    "    cent_aen = geometric_median(np.asarray(dist_aen_tfidf.todense())).reshape(1,-1)\n",
    "\n",
    "    ad_vec = tfidf.transform([ad_chunk])\n",
    "    ad_dist_puni = pairwise_distances(cent_puni, ad_vec, metric='l2')[0][0]\n",
    "    ad_dist_aen = pairwise_distances(cent_aen, ad_vec, metric='l2')[0][0]\n",
    "\n",
    "    print(\"Addit distance from Puni centroid: %.4f\" % ad_dist_puni)\n",
    "    print(\"Addit distance from Aeneid centroid: %.4f\" % ad_dist_aen)\n",
    "\n",
    "    print(\"Distance from Puni centroid to Aeneid centroid: %.4f\" % pairwise_distances(cent_aen, cent_puni, metric='l2')[0][0])\n",
    "\n",
    "    aen_dists = [pairwise_distances(cent_aen, x.reshape(1,-1), metric='l2')[0][0] for x in puni_dist_tfidf]\n",
    "    print(\"Percentage of PUNICA points CLOSER to Aeneid (than Addit): %2.2f\" % (len([x for x in aen_dists if x < ad_dist_aen])/len(aen_dists)*100))\n",
    "\n",
    "    puni_dists = [pairwise_distances(cent_puni, x.reshape(1,-1), metric='l2')[0][0] for x in puni_dist_tfidf]\n",
    "    print(\"Percentage of PUNICA points FURTHER from Punica (than Addit): %2.2f\" % (len([x for x in puni_dists if x > ad_dist_puni])/len(puni_dists)*100))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other approaches - OneClassSVM\n",
    "\n",
    "SVMs with linear kernels scale well to large dimensions, and have been used for outlier detection, with the most common being the One-class SVM. In the experiment below we find the following:\n",
    "- With the _Additamentum_ included, we trained a `OneClassSVM` on a sampled distribution of 5000 contiguous 81-line chunks from the _Punica_. At the 95% confidence level it was detected as an inlier.\n",
    "- Without the _Additamentum_ in the training data (training only on securely Silian text) it is detected as an outlier at the same threshold.\n",
    "- If the _Additamentum_ is spliced into the _Aeneid_ it is detected as an _inlier_, but an outlier if not.\n",
    "\n",
    "Based on this I suggest that the _Additamentum_ is right at the edge of the threshold in terms of stylistic similarity to _both_ the _Aeneid_ and the _Punica_ but in fact is an outlier from both texts at the 95% confidence level. Again, this is consistent with the work of an interpolator trained on Vergil who is attempting (and doing an excellent job) to imitate Silius.\n",
    "\n",
    "Again, this result is NOT reported in the paper because I do not consider it to be a 'secure' $P$-value. The statistical hypothesis when setting up a One-class SVM with a given contamination level is...complex. Perhaps I am being too conservative here.\n",
    "\n",
    "Based on this and many other tests conducted on this data (various other metric tests, work with multiclass classifiers, other outlier detection methods...) I remain confident in the general finding:\n",
    "\n",
    "### The _Additamentum_ is right at the edge of the detectable stylistic boundary of _both_ the _Aeneid_ and the _Punica_ when considering lexico-grammatical style as reflected by LSA. Nevertheless, it is an outlier from both works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:04:59.765351Z",
     "iopub.status.busy": "2021-07-04T04:04:59.760777Z",
     "iopub.status.idle": "2021-07-04T04:04:59.835192Z",
     "shell.execute_reply": "2021-07-04T04:04:59.834250Z",
     "shell.execute_reply.started": "2021-07-04T04:04:59.765188Z"
    }
   },
   "outputs": [],
   "source": [
    "def howmany(key, corpus):\n",
    "    _, work = key.split('--')\n",
    "    return len(corpus[corpus.Work==work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:04:59.843380Z",
     "iopub.status.busy": "2021-07-04T04:04:59.842009Z",
     "iopub.status.idle": "2021-07-04T04:04:59.972403Z",
     "shell.execute_reply": "2021-07-04T04:04:59.970071Z",
     "shell.execute_reply.started": "2021-07-04T04:04:59.843225Z"
    }
   },
   "outputs": [],
   "source": [
    "def oneclass_svm_experiment(corpus_ll, addit_ll, insert_at=None, comp_corpus=corpus_A, n=5000, contamination=0.05):\n",
    "    '''\n",
    "    For the given corpus, perform the following experiment using a One Class SVM for outlier\n",
    "    detection:\n",
    "      * Create a sampled distribution of n chunks of 81 lines from the work given\n",
    "      * TF-IDF transform the sample\n",
    "      * Train a One Class SVM on the transformed sample at full dimensionality\n",
    "      * Predict FROM THE ORIGINAL CORPUS which chunks are inliers\n",
    "      * Repeat the steps above, but with the Additamentum spliced into the middle of the lines\n",
    "    '''\n",
    "    \n",
    "    print(\"Running at %.1f%% contamination, sample n=%d\\n\" % (contamination*100, n))\n",
    "    \n",
    "    tfidf = TfidfVectorizer(\n",
    "        sublinear_tf=True, \n",
    "        use_idf=True,\n",
    "        norm='l2', \n",
    "        analyzer='char',\n",
    "        ngram_range=(2,4)\n",
    "    )\n",
    "    \n",
    "    if not insert_at:\n",
    "        insert_at = len(corpus_ll)//2\n",
    "    if insert_at+81 > len(corpus_ll):\n",
    "        raise ValueError(\"Trying to insert past end of text\")\n",
    "        \n",
    "    # Run 1\n",
    "    print(\"Run 1 -- Training on text only\")\n",
    "    dist = sample_chunks(corpus_ll, n, 81, np.random.RandomState(seed=1234))\n",
    "    dist_tfidf = tfidf.fit_transform(dist)\n",
    "    # The RBF kernel is generally as good or better but linear kernel is MUCH\n",
    "    # faster, and the dimensionality is high here. In other tests, linear\n",
    "    # and rbf SVMs for classification were both so accurate as to be indistinguishable\n",
    "    ocsvm = OneClassSVM(nu=contamination, kernel=\"linear\",gamma='scale')\n",
    "    ocsvm.fit(dist_tfidf)\n",
    "    corpus_preds = ocsvm.predict(tfidf.transform(comp_corpus.Chunk))\n",
    "    # select the rows from the original corpus at the locations where the\n",
    "    # prediction vector is '1' (for inlier)\n",
    "    keys = comp_corpus.loc[corpus_preds==1][['Author','Work']].agg('--'.join, axis=1)\n",
    "    ctr = Counter(keys)\n",
    "    preds = '\\n'.join([\"  %s: %d/%d\" % (k,v,howmany(k,comp_corpus)) for (k,v) in  ctr.items()])\n",
    "    print(\"Chunks detected as inliers:\\n%s\\n\" % preds)\n",
    "    \n",
    "    # Run 2\n",
    "    \n",
    "    print(\"Run 2 -- Splicing Additamentum into training text at line %d\" % insert_at)\n",
    "    spliced = corpus_ll[:insert_at] + addit_ll + corpus_ll[insert_at:]\n",
    "    dist = sample_chunks(spliced, n, 81, np.random.RandomState(seed=1234))\n",
    "    dist_tfidf = tfidf.fit_transform(dist)\n",
    "    ocsvm = OneClassSVM(nu=contamination, kernel=\"linear\",gamma='scale')\n",
    "    ocsvm.fit(dist_tfidf)\n",
    "    corpus_preds = ocsvm.predict(tfidf.transform(comp_corpus.Chunk))\n",
    "    keys = comp_corpus.loc[corpus_preds==1][['Author','Work']].agg('--'.join, axis=1)\n",
    "    ctr = Counter(keys)\n",
    "    preds = '\\n'.join([\"  %s: %d/%d\" % (k,v,howmany(k,comp_corpus)) for (k,v) in  ctr.items()])\n",
    "    print(\"Chunks detected as inliers:\\n%s\\n\" % preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Description\n",
    "\n",
    "For the given corpus, perform the following experiment using a One Class SVM for outlier\n",
    "detection:\n",
    "  * Create a sampled distribution of n chunks of 81 lines from the work given\n",
    "  * TF-IDF transform the sample\n",
    "  * Train a One Class SVM on the transformed sample at full dimensionality\n",
    "  * Predict FROM THE ORIGINAL CORPUS which chunks are inliers\n",
    "  * Repeat the steps above, but with the Additamentum spliced into the middle of the lines\n",
    "  \n",
    "So, eg, when we train on the _Punica_, and then use that classifier to examine the entire corpus, it picks 136/150 of the real Punica chunks, and also a few chunks of the Aeneid, Thebaid and Pharsalia (all works to which Silius has known intertextual links). When trained on the _Aeneid_ it likewise picks most of those chunks as well as a few of Silius, Ovid and Statius. The results seem more or less as expected. Remember that the `OneClassSVM` is trained with a contamination value of 5% and so it would be expected to reject 5% of the chunks of genuine Silius (actually it rejects ~10%) or the genuine _Aeneid_ (it rejects very close to 5%). Silius is more varible in lexico-grammatical style than Vergil in the _Aeneid_.\n",
    "\n",
    "### NOTE: Hacking random results\n",
    "\n",
    "Choosing exactly where to insert the Addit raises the spectre of \"result hacking\", which indeed it is. In fact, when inserted in the exact middle of both texts it was detected as an outlier in both cases (when included in the training data and when omitted). Given that I wanted to demonstrate that _sometimes_ it is detected as an inlier, I had to choose values where that happened. Essentially I am hacking the results to force them to display a weakness (if the Addit were always detected as an outlier that would be a stronger result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:05:00.073682Z",
     "iopub.status.busy": "2021-07-04T04:05:00.073101Z",
     "iopub.status.idle": "2021-07-04T04:09:59.394996Z",
     "shell.execute_reply": "2021-07-04T04:09:59.394280Z",
     "shell.execute_reply.started": "2021-07-04T04:05:00.073514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 5.0% contamination, sample n=5000\n",
      "\n",
      "Run 1 -- Training on text only\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 3/121\n",
      "  Silius--Punica: 136/150\n",
      "  Statius--Thebaid: 2/120\n",
      "  Lucan--Pharsalia: 6/99\n",
      "\n",
      "Run 2 -- Splicing Additamentum into training text at line 5230\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 3/121\n",
      "  Silius--Punica: 138/150\n",
      "  Unknown--Punica: 1/150\n",
      "  Statius--Thebaid: 2/120\n",
      "  Lucan--Pharsalia: 7/99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneclass_svm_experiment(puni_na, addit_lines, insert_at=5230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:09:59.396932Z",
     "iopub.status.busy": "2021-07-04T04:09:59.396484Z",
     "iopub.status.idle": "2021-07-04T04:15:00.546298Z",
     "shell.execute_reply": "2021-07-04T04:15:00.545178Z",
     "shell.execute_reply.started": "2021-07-04T04:09:59.396864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 5.0% contamination, sample n=5000\n",
      "\n",
      "Run 1 -- Training on text only\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 115/121\n",
      "  Ovid--Metamorphoses: 2/148\n",
      "  Silius--Punica: 9/150\n",
      "  Statius--Thebaid: 4/120\n",
      "\n",
      "Run 2 -- Splicing Additamentum into training text at line 5000\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 115/121\n",
      "  Ovid--Metamorphoses: 2/148\n",
      "  Silius--Punica: 11/150\n",
      "  Unknown--Punica: 1/150\n",
      "  Statius--Thebaid: 4/120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneclass_svm_experiment(aen_ll_np, addit_lines, insert_at=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:15:00.547655Z",
     "iopub.status.busy": "2021-07-04T04:15:00.547341Z",
     "iopub.status.idle": "2021-07-04T04:19:58.314942Z",
     "shell.execute_reply": "2021-07-04T04:19:58.313826Z",
     "shell.execute_reply.started": "2021-07-04T04:15:00.547608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 5.0% contamination, sample n=5000\n",
      "\n",
      "Run 1 -- Training on text only\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 3/121\n",
      "  Silius--Punica: 136/150\n",
      "  Statius--Thebaid: 2/120\n",
      "  Lucan--Pharsalia: 6/99\n",
      "\n",
      "Run 2 -- Splicing Additamentum into training text at line 6059\n",
      "Chunks detected as inliers:\n",
      "  Vergil--Aeneid: 2/121\n",
      "  Silius--Punica: 139/150\n",
      "  Statius--Thebaid: 2/120\n",
      "  Lucan--Pharsalia: 6/99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just splicing in the Addit to the Punica isn't enough to ensure it will be detected as\n",
    "# an inlier, it is sensitive to the location and the random sample. This seems to be\n",
    "# further evidence that it is right on the stylistic border.\n",
    "\n",
    "oneclass_svm_experiment(puni_na, addit_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Approaches - Multiclass Classifier Experiments\n",
    "\n",
    "This last exploration is in support of the claim that the style is closer to the Aeneid than the Punica, and much more in imitation of Vergil than Silius' general style. It should first be emphasised that in a multi-class classification, the computer is forced to choose between a fixed set of labels, it can't guess 'non of the above' (which is what is being claimed, ie that the Addit is by an unknown interpolator). There is no possibility, obviously, that the style is actually Vergilian, simply that the algorithm thinks it is _more like Vergil than Silius_. \n",
    "\n",
    "Classifiers are not really good ways to support (or refute) claims of non-genuineness. The experiments below are offered simply in the spirit of open investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:19:58.316851Z",
     "iopub.status.busy": "2021-07-04T04:19:58.316231Z",
     "iopub.status.idle": "2021-07-04T04:19:58.333560Z",
     "shell.execute_reply": "2021-07-04T04:19:58.327490Z",
     "shell.execute_reply.started": "2021-07-04T04:19:58.316544Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    '''\n",
    "    Calculate the 95% confidence interval around the mean for an array of numbers.\n",
    "    Uses one-sample T-test.\n",
    "    '''\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), sp.stats.sem(a)\n",
    "    h = se * sp.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:19:58.335839Z",
     "iopub.status.busy": "2021-07-04T04:19:58.335194Z",
     "iopub.status.idle": "2021-07-04T04:19:58.368321Z",
     "shell.execute_reply": "2021-07-04T04:19:58.361486Z",
     "shell.execute_reply.started": "2021-07-04T04:19:58.335738Z"
    }
   },
   "outputs": [],
   "source": [
    "def classifier_test(clf, corp, test_chunk, use_svd=True, do_cv=True, refits=10, fit_dist=True):\n",
    "    \n",
    "    p=None\n",
    "    rng = np.random.RandomState(seed=1234)\n",
    "    \n",
    "    if use_svd:\n",
    "        print(\"Running SVD at 180 dimensions.\")\n",
    "        p = make_pipeline(\n",
    "            TfidfVectorizer(sublinear_tf=True, use_idf=True, norm='l2', analyzer='char', ngram_range=(2,4)),\n",
    "            TruncatedSVD(180, random_state=rng),\n",
    "            Normalizer(copy=False),\n",
    "            clf,\n",
    "        )\n",
    "    else:\n",
    "        print(\"Running at full dimensionality.\")\n",
    "        p = make_pipeline(\n",
    "            TfidfVectorizer(sublinear_tf=True, use_idf=True, norm='l2', analyzer='char', ngram_range=(2,4)),\n",
    "            clf,\n",
    "        )\n",
    "        \n",
    "    print(\"Testing Classifier: %s\" % clf)\n",
    "    clf_res = {'Author':[], 'Work':{}}\n",
    "    if do_cv:\n",
    "        print(\"Doing 10 fold CV with 80/20 split, recall weighted\")\n",
    "        s = cross_val_score(p, corp.Chunk, corp.Work, cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2), n_jobs=-1, scoring='recall_weighted')\n",
    "        m,h = mean_confidence_interval(s)\n",
    "        clf_res['Work']=[m,h]\n",
    "        print(\"Accuracy (Work): %.2f%% ± %.3f\" % (m*100, h*100))\n",
    "        s = cross_val_score(p, corp.Chunk, corp.Author, cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2), n_jobs=-1, scoring='recall_weighted')\n",
    "        m,h = mean_confidence_interval(s)\n",
    "        clf_res['Author']=[m,h]\n",
    "        print(\"Accuracy (Author): %.2f%% ± %.3f\" % (m*100, h*100))\n",
    "        \n",
    "    print(\"Refitting %d times\" % refits)\n",
    "    pred_auths, pred_works = [], []\n",
    "    for _ in range(refits):\n",
    "        p.fit(corp.Chunk, corp.Author)\n",
    "        pred_auths.append(p.predict([test_chunk])[0])\n",
    "        p.fit(corp.Chunk, corp.Work)\n",
    "        pred_works.append(p.predict([test_chunk])[0])\n",
    "    print(\"Predicting for the test chunk. Author: %s. Work: %s.\" % (Counter(pred_auths), Counter(pred_works)))\n",
    "    \n",
    "    # How many random chunks of securely attributed Punica are predicted as something else?\n",
    "    dist_preds = Counter([])\n",
    "    if fit_dist:\n",
    "        p.fit(corp.Chunk, corp.Work)\n",
    "        dist_works = Counter(p.predict(DIST_PUNI_NA_10K))\n",
    "        p.fit(corp.Chunk, corp.Author)\n",
    "        dist_auths = Counter(p.predict(DIST_PUNI_NA_10K))\n",
    "        print(\"Predicting for 10,000 random Punica Chunks. Author: %s. Work: %s\" % (dist_auths, dist_works))\n",
    "    \n",
    "    #return (clf_res, pred_auths, pred_works, dist_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification with K-Nearest Neighbours\n",
    "\n",
    "Since we have decided that distance-metric measures are unstable in the SVD space but the _local_ topology seems OK (it's still some kind of Riemannian manifold)  I experiment here with K-Nearest Neighbours, as well as some other classifiers that are generally considered suitable for high dimension problems.\n",
    "\n",
    "We work here with two corpora. Since this is a classification test, we use `corpus_C` as a base, since we can't have the chunk of interest (the Addit) in the training data. I also test with a subset of `corpus_C` containing ONLY the _Aeneid_ and the _Punica_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:19:58.370245Z",
     "iopub.status.busy": "2021-07-04T04:19:58.369807Z",
     "iopub.status.idle": "2021-07-04T04:19:58.433166Z",
     "shell.execute_reply": "2021-07-04T04:19:58.418091Z",
     "shell.execute_reply.started": "2021-07-04T04:19:58.370114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.431676725154983"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One heuristic for KNN is to use sqrt(n) neighbours, but the best approach always depepnds on the data.\n",
    "\n",
    "aenpu = corpus_C.query('Work==\"Aeneid\" or Work==\"Punica\"')\n",
    "math.sqrt(len(aenpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours predicts the Additamentum to be the _Aeneid_ with low K\n",
    "\n",
    "At higher values of K the value changes to predict the _Punica_. Again this seems consistent with the idea that the Additamentum is at the stylistic boundary between the works. However when the results for 10,000 random contiguous chunks of the (securely attributed) Punica are predicted at $K=5$, none of them are predicted as the Aeneid. \n",
    "\n",
    "### This again supports the conclusion that whatever the prediction result (and clearly the predictions vary by classifier and by parameter selection), the _Additamentum_ chunk is much closer to the style of the _Aeneid_ than typical Silian style.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:19:58.436185Z",
     "iopub.status.busy": "2021-07-04T04:19:58.434521Z",
     "iopub.status.idle": "2021-07-04T04:23:43.602976Z",
     "shell.execute_reply": "2021-07-04T04:23:43.602041Z",
     "shell.execute_reply.started": "2021-07-04T04:19:58.436061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at full dimensionality.\n",
      "Testing Classifier: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "Doing 10 fold CV with 80/20 split, recall weighted\n",
      "Accuracy (Work): 98.89% ± 0.926\n",
      "Accuracy (Author): 98.15% ± 1.396\n",
      "Refitting 1 times\n",
      "Predicting for the test chunk. Author: Counter({'Vergil': 1}). Work: Counter({'Aeneid': 1}).\n",
      "Predicting for 10,000 random Punica Chunks. Author: Counter({'Silius': 10000}). Work: Counter({'Punica': 10000})\n"
     ]
    }
   ],
   "source": [
    "classifier_test(KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean'), aenpu, ad_chunk, do_cv=True, use_svd=False, refits=1, fit_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:23:43.604505Z",
     "iopub.status.busy": "2021-07-04T04:23:43.604199Z",
     "iopub.status.idle": "2021-07-04T04:24:13.114836Z",
     "shell.execute_reply": "2021-07-04T04:24:13.111423Z",
     "shell.execute_reply.started": "2021-07-04T04:23:43.604381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at full dimensionality.\n",
      "Testing Classifier: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n",
      "                     weights='uniform')\n",
      "Doing 10 fold CV with 80/20 split, recall weighted\n",
      "Accuracy (Work): 100.00% ± 0.000\n",
      "Accuracy (Author): 99.63% ± 0.559\n",
      "Refitting 1 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 1}). Work: Counter({'Punica': 1}).\n"
     ]
    }
   ],
   "source": [
    "classifier_test(KNeighborsClassifier(n_neighbors=17), aenpu, ad_chunk, do_cv=True, use_svd=False, refits=1, fit_dist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:24:13.116180Z",
     "iopub.status.busy": "2021-07-04T04:24:13.115956Z",
     "iopub.status.idle": "2021-07-04T04:29:49.357157Z",
     "shell.execute_reply": "2021-07-04T04:29:49.356199Z",
     "shell.execute_reply.started": "2021-07-04T04:24:13.116143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at full dimensionality.\n",
      "Testing Classifier: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "Doing 10 fold CV with 80/20 split, recall weighted\n",
      "Accuracy (Work): 96.23% ± 1.162\n",
      "Accuracy (Author): 97.11% ± 0.905\n",
      "Refitting 1 times\n",
      "Predicting for the test chunk. Author: Counter({'Vergil': 1}). Work: Counter({'Aeneid': 1}).\n",
      "Predicting for 10,000 random Punica Chunks. Author: Counter({'Silius': 9954, 'Lucan': 46}). Work: Counter({'Punica': 9954, 'Pharsalia': 46})\n"
     ]
    }
   ],
   "source": [
    "classifier_test(KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean'), corpus_C, ad_chunk, do_cv=True, use_svd=False, refits=1, fit_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:29:49.358704Z",
     "iopub.status.busy": "2021-07-04T04:29:49.358143Z",
     "iopub.status.idle": "2021-07-04T04:31:15.331414Z",
     "shell.execute_reply": "2021-07-04T04:31:15.329961Z",
     "shell.execute_reply.started": "2021-07-04T04:29:49.358318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at full dimensionality.\n",
      "Testing Classifier: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n",
      "                     weights='distance')\n",
      "Doing 10 fold CV with 80/20 split, recall weighted\n",
      "Accuracy (Work): 96.73% ± 0.664\n",
      "Accuracy (Author): 98.62% ± 0.592\n",
      "Refitting 1 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 1}). Work: Counter({'Punica': 1}).\n"
     ]
    }
   ],
   "source": [
    "classifier_test(KNeighborsClassifier(n_neighbors=17, weights='distance', metric='euclidean'), corpus_C, ad_chunk, do_cv=True, use_svd=False, refits=1, fit_dist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Classifier Results\n",
    "\n",
    "We test a set of classifiers that are suitable for large-scale learning problems (problems with very high numbers of samples or (in this case) large numbers of features). Some classifiers predict that the Addit is from the _Punica_, some from the _Aeneid_. In many cases the outcome depends on various stochastic processes that occur in the operation of the classifier. Again, the _Additamentum_ is much closer to the border between Silius and Vergil than 'typical' Silian verse.\n",
    "\n",
    "## Reminder: Classifiers are not well suited for positive genuineness arguments\n",
    "\n",
    "It is tempting to see results like \"the Addit is detected as Silius 7 times and Vergil 3 times, so it is 70% likely to be by Silius\". This is not the correct interpretation. If the text is by neither author the algorithm is still forced to make a choice, and so it picks the author to which the lexico-grammatical features are most similar. If the Addit is by a Humanist interpolator, educated with a level of Latineity almost inconceivable to us, then it is not surprising that the text is similar to genuine Silian style. The argument I am continuing here is that the style is more Vergilian in general than typical Silius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:31:15.337875Z",
     "iopub.status.busy": "2021-07-04T04:31:15.332987Z",
     "iopub.status.idle": "2021-07-04T04:34:57.679893Z",
     "shell.execute_reply": "2021-07-04T04:34:57.678308Z",
     "shell.execute_reply.started": "2021-07-04T04:31:15.337797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=RandomState(MT19937) at 0x12268D050,\n",
      "           shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "           warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 6, 'Vergil': 4}). Work: Counter({'Punica': 9, 'Aeneid': 1}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='squared_hinge', max_iter=1000,\n",
      "                            n_iter_no_change=5, n_jobs=None,\n",
      "                            random_state=RandomState(MT19937) at 0x12268D050,\n",
      "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "                            verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 10}). Work: Counter({'Punica': 10}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None,\n",
      "                            random_state=RandomState(MT19937) at 0x12268D050,\n",
      "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "                            verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 10}). Work: Counter({'Punica': 9, 'Aeneid': 1}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=RandomState(MT19937) at 0x12268D050,\n",
      "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "              warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 8, 'Vergil': 2}). Work: Counter({'Punica': 7, 'Aeneid': 3}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=RandomState(MT19937) at 0x12268D050, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 10}). Work: Counter({'Punica': 9, 'Aeneid': 1}).\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(seed=1234)\n",
    "clfs = [\n",
    "    (Perceptron(random_state=rng), None),\n",
    "    (PassiveAggressiveClassifier(loss='squared_hinge',random_state=rng), None),\n",
    "    (PassiveAggressiveClassifier(loss='hinge',random_state=rng), None),\n",
    "    (SGDClassifier(loss='hinge',random_state=rng), None),\n",
    "    (SGDClassifier(loss='log',random_state=rng), None),\n",
    "]\n",
    "\n",
    "for (c,dims) in clfs:\n",
    "    print('-'*40)\n",
    "    print()\n",
    "    classifier_test(c, aenpu, ad_chunk, do_cv=False, use_svd=False, refits=10, fit_dist=False)\n",
    "    print()\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T04:34:57.681714Z",
     "iopub.status.busy": "2021-07-04T04:34:57.681390Z",
     "iopub.status.idle": "2021-07-04T04:45:57.970626Z",
     "shell.execute_reply": "2021-07-04T04:45:57.968959Z",
     "shell.execute_reply.started": "2021-07-04T04:34:57.681658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=RandomState(MT19937) at 0x12268D160,\n",
      "           shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "           warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 5, 'Vergil': 4, 'Juvenal': 1}). Work: Counter({'Punica': 6, 'Aeneid': 4}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='squared_hinge', max_iter=1000,\n",
      "                            n_iter_no_change=5, n_jobs=None,\n",
      "                            random_state=RandomState(MT19937) at 0x12268D160,\n",
      "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "                            verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 10}). Work: Counter({'Punica': 10}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None,\n",
      "                            random_state=RandomState(MT19937) at 0x12268D160,\n",
      "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "                            verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 10}). Work: Counter({'Punica': 10}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=RandomState(MT19937) at 0x12268D160,\n",
      "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "              warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 7, 'Vergil': 3}). Work: Counter({'Punica': 8, 'Aeneid': 2}).\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Running at full dimensionality.\n",
      "Testing Classifier: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=RandomState(MT19937) at 0x12268D160, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Refitting 10 times\n",
      "Predicting for the test chunk. Author: Counter({'Silius': 9, 'Vergil': 1}). Work: Counter({'Punica': 10}).\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(seed=1234)\n",
    "clfs = [\n",
    "    (Perceptron(random_state=rng), None),\n",
    "    (PassiveAggressiveClassifier(loss='squared_hinge',random_state=rng), None),\n",
    "    (PassiveAggressiveClassifier(loss='hinge',random_state=rng), None),\n",
    "    (SGDClassifier(loss='hinge',random_state=rng), None),\n",
    "    (SGDClassifier(loss='log',random_state=rng), None),\n",
    "]\n",
    "\n",
    "for (c,dims) in clfs:\n",
    "    print('-'*40)\n",
    "    print()\n",
    "    classifier_test(c, corpus_C, ad_chunk, do_cv=False, use_svd=False, refits=10, fit_dist=False)\n",
    "    print()\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The results of the various experiments are open to interpretation, and verification or extension is welcomed. Overall, I take the results here to support the general claim that the style of the Additamentum is significantly more Vergilian than typical Silian style, consistent with interpolation.\n",
    "\n",
    "- I am not convinced that the original experiment is invalid, I am simply cautious. In any case, the experiment with `corpus_C` also suggests that the _Additamentum_ is a statistical outlier, although that might seem counterintuitive.\n",
    "- The `OneClassSVM` results show that the _Additamentum_ is an outlier from both works. However to convert that result to a 'hard' $P$-value seems difficult.\n",
    "- The `KNearestNeighbours` results seem to also indicate that the majority of small-scale nearest neighbours are from the _Aeneid_, something that random chunks of the _Punica_ almost never exhibit. This is reflected in the UMAP results (indeed UMAP attempts to make a manifold projection, which preserves local topology in preference to global topology. KNN is the closest match to this idea). This supports the claim that \"the style is unusually Vergilian\".\n",
    "- Other classifiers support the idea that the _Additamentum_ is a borderline choice between the _Aeneid_ and the _Punica_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silius",
   "language": "python",
   "name": "silius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
